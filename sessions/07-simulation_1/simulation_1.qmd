---
title: "Intro to microsimulation"
subtitle: "EPIB  676 session 7, McGill University"
author: "Alton Russell"
date: "27 Jan 2026"
format: revealjs
editor: visual
---

## R packages

```{r}
#| echo: true
library(fitdistrplus) #fit distributions to data
library(rriskDistributions) #fit distributions given quantiles
library(dplyr) #use rename, mutate
library(ggplot2)
```

## Today

-   [**Wrapping up reproducible research with Quarto**]{.underline}

-   Microsimulation basics

-   Sampling

-   Convergence

-   Simulating decision trees

## Wrapping up reproducible research with Quarto

<https://htmlpreview.github.io/?https://github.com/altonrus/epib-678/blob/main/sessions/06-modeling_workflow/modeling_workflow.html#/screenshot-of-knit-manuscript>

## Today

-   [**Microsimulation basics**]{.underline}

-   Sampling

-   Convergence

-   Simulating decision trees

## State explosion: a limit of cohort models

To add heterogeneity in cohort model

-   Add states

-   Make separate model versions (e.g., 40, 50, 60 year old starting age, male and female)

Can quickly become unwieldy:

8 heath states, 2 genders, 4 racial groups, 8 age groups = **512 states!**

## Advantage of microsimulation models

-   Explicitly model **individuals**, not cohorts

-   Capture individual (patient) variation

-   Model diverse pathways

-   Individuals' history can impact future events

    -   No Markov assumption

## Monte Carlo simulation

Repeated sampling of random numbers to estimate a quantity. Used in risk analysis, physics, integration, etc.

::::: columns
::: {.column width="65%"}
**General process**

-   Identify inputs and assign distributions

-   For several (1000's of) repetitions:

    -   Sample inputs

    -   Compute outcome(s)

-   Aggregate results
:::

::: {.column width="35%"}
![](figs/monte_carlo_gif_wiki.gif)
:::
:::::

## Monte Carlo to estimate $\pi$

::::: columns
::: {.column width="50%"}
![](figs/pi_monte_carlo1_berkorbay.png)
:::

::: {.column width="50%"}
![](figs/pi_monte_carlo2_berkorbay.png)
:::
:::::

Source: [Berk Orbay](https://berkorbay.github.io/fe522/02_Monte_Carlo_Simulation.html)

## Code for estimating $\pi$

```{r}
#| echo: true
monte_carlo_pi = function(N) {
  hits = 0
  for (i in 1:N) {
    u1 = runif(1)
    u2 = runif(1)
    if (sqrt(u1^2 + u2^2) <=1 ){
      hits = hits + 1
    }
  }
  return(4*hits / N)
}
N = 500000
monte_carlo_pi(N)
```

## Patient Monte Carlo simulation

-   Identify **inputs** and assign distributions

    -   Patient characteristics

    -   Risks, costs, health impact of uncertain events

    -   Impact of health intervention on risks/costs/health impacts

-   For 1000's of repetitions:

    -   Generate a patient

    -   Simulate their outcomes (under \>1 strategy)

-   Aggregate population outcomes under each strategy

## Microsimulation defined

-   Simulates individuals (usually patients)

-   Tracks characteristics, health states, outcomes

-   [No interaction]{.underline} between individuals

    -   Contagion $\rightarrow$ agent based simulation
    -   Capacity/queues $\rightarrow$ discrete event simulation

::: callout-note
Some use different terminology and consider agent base or discrete event models subsets of microsimulations
:::

## "Memory" in a microsimulation

Risks, costs, and health outcomes can depend on any variable you choose to track:

-   Patients' baseline characteristics

-   Simulation time (or patient age)

-   Patient's path up until that point

    -   Risk differs based on number of prior cancers, overdoses, relapses...

Think [**conditional distributions**]{.underline} (given age, sex, history, etc.)

## Variation: microsim vs. cohort

**Cohort model**

-   Population is homogeneous within a health state

-   Parameters reflect population averages

**Microsimulation**

-   Parameterization **can** reflect individual-level variation

-   "X% of patients would have costs over \$Y" or "adverse event would occur in X% of patients from Y subgroup"

[**But**]{.underline}, only capture full variability if parameterized to do so

## Downside: complexity and compute

-   Flexibility & functionality comes with complexity

-   Can be harder to program, parameterize, debug

-   Long runtime, particularly with rare events and without code optimization

[**Strategy:**]{.underline} get a minimally viable model working, add complexity where warranted

## Key microsimulation components

[**Vector of individual variables**]{.underline}

-   Baseline characteristics (e.g., age, sex, race, initial cancer stage, CD4 count...)

-   History-tracking variables (e.g., costs, QALYs, infections, recurrences, transfusions...)

[**Model parameters:**]{.underline} probabilities, distributions over outcomes

[**Model:**]{.underline} function that generates individuals and applies parameters to calculate outcomes

## Today

-   Microsimulation basics

-   [**Sampling**]{.underline}

-   Convergence

-   Simulating decision trees

## Two levels of uncertainty

-   **Stochasticity:** individual variation in outcomes due to random chance

-   **Parametric uncertainty:** about a population parameter

Example:

-   My risk of getting cancer? $\rightarrow$ parametric uncertainty

-   Will I get cancer? $\rightarrow$ stochasticity

[Stochasticity]{.underline} occurs within a microsimulation run. Parametric uncertainty assessed through sensitivity analysis (more later)

## Bayesian analog

Posterior distribution describes **parameteric uncertainty**. Sampling distribution describes **stochasticity**.

![[Statistical Rethinking Ch. 3 by Richard McElreath](https://xcelab.net/rm/statistical-rethinking/)](figs/sampling_dists_posterior_statisticalRethinking.png)

## Two options for sampling

-   **Sampling from distributions**

-   Sampling from datasets

## Sampling a binary outcome

[**Parameter**]{.underline}: probability the outcome happens

Option 1: binomial distribution

```{r}
#| echo: true
#Sampling gender for 100 simulants (rbinomial)
p_female = 0.7
v_isFemale <- rbinom(n=100, size=1, p=p_female)
sum(v_isFemale)
```

Option 2: sampling from uniform distribution

```{r}
#| echo: true
#Sampling gender for 100 simulants (runif)
v_isFemale <- ifelse(runif(n=100) < 0.7, 1, 0)
sum(v_isFemale)
```

## Sampling discrete multiclass outcome

[**Parameters**]{.underline}: probability for each outcome (or all but one outcome)

```{r}
#| echo: true
race_dist <- c(0.1, 0.05, 0.2, 0.15, 0.4)
names(race_dist) <- c("black", "indigenous", "latino","other", "white")

#Use sample function with prob argument
v_race = sample(x=names(race_dist), size=100, prob=race_dist, replace=T)

# Number simulants in each race category
table(v_race)
# Distribution of race in simulated population
table(v_race)/length(v_race)
```

## Sampling from empirical dist'n

Equivalent to directly sampling a single variable from data

```{r}
#| echo: true
v_emp_cost_per_pt <- c(240, 345, 191, 560, 434, 123, 640, 260, 257, 231, 1100, 503)
cost_emp_dist <- ecdf(v_emp_cost_per_pt)
plot(cost_emp_dist)

# Can sample with replacement
sample(v_emp_cost_per_pt, size=10, replace = T)
```

## Fitting distribution to data

**fitdistrplus** package accepts these distributions: "norm", "lnorm", "pois", "exp", "gamma", "nbinom", "geom", "beta", "unif" and "logis"

```{r}
#| echo: true
dist_cost_gamma <- fitdist(v_emp_cost_per_pt, distr="gamma",method="mle")
summary(dist_cost_gamma)
```

## Fitting distribution to data

```{r}
#| echo: true
plot(dist_cost_gamma)
```

## Fitting distribution to quantiles

Can also fit distribution to summary statistics reported in literature, such as quantiles

```{r}
#| echo: true
#GIVEN: Median = $400, IQR [$300, $600]
dist_cost_lnorm <- get.lnorm.par(p=c(.25, .5, .75),
                            q=c(300, 400, 600), show.output = F)
```

## Correlated parameters

Probabilities, costs, health outcomes can be correlated, could depend on baseline characteristics or history

-   Can fit distribution separately by subgroup

    -   $P(X \mid \text{age, sex, number of remissions})$

    -   $Cost(Y \mid \text{recurrences, age})$

-   Or derive estimate of joint distribution

    -   Iterative proportional fitting [(Husby et. al. 2018)](https://www.microsimulation.pub/articles/00184)

    -   Copulas [(Jeong et al 2015)](https://doi.org/10.1371/journal.pone.0159496)

    -   Bayesian parameter calibration (session 13)

## Sample directly or fit distribution?

[Why sample directly?]{.underline}

-   No assumptions

-   Sampling \>1 variable for each individual maintains correlation without fancy modeling

[Why fit distribution (even if you have data)?]{.underline}

-   Small or biased samples may not include full variability of target population

-   Don't need to load data into memory to run model (efficient)

-   Others can run your model even if data cannot be shared

## Today

-   Microsimulation basics

-   Sampling

-   [**Convergence**]{.underline}

-   Simulating decision trees

## How many patients to simulate?

-   Population estimates of interest should not depend on stochasticity (which random numbers happened to be used in a simulation repitition)

-   Should simulate enough patients (or repetitions) such that that error due to stochasticity is negligible

-   Options for assessing?

    1.  Calculate Monte Carlo Standard Error

    2.  Run simulation multiple times with different seeds

    3.  Bootstrap resampling

## Running model multiple times

```{r}
#| echo: true
N=1000
set.seed(100); a = monte_carlo_pi(N)
set.seed(200); b = monte_carlo_pi(N)
set.seed(300); c = monte_carlo_pi(N)

mean(a)
mean(b)
mean(c)
```

## Monte Carlo standard error

For some model outcome $\hat{x}$ (e.g., total or incremental cost or QALy; ICER; etc), the Monte Carlo standard error (MCSE) quantifies variability in $E(X)$ across $N$ simulated individuals due to stochasticity.

$$
\text{MCSE} = \sqrt{\frac{\text{Var}(\hat{x})}{N}}
$$

MCSE goes to 0 as N goes to infinity

## Monte Carlo standard error

To demonstrate, we need a new version of `monte_carlo_pi()` that outputs a vector of all repetitions of the simulation

```{r}
#| echo: true
mcSim_pi_repetitions = function(N) {
  4*(sqrt(runif(N)^2 + runif(N)^2) <=1)
}
mc_output_1000 = mcSim_pi_repetitions(1000)

head(mc_output_1000)
mean(mc_output_1000)

mc_output_100000 = mcSim_pi_repetitions(100000)
mean(mc_output_100000)
```

## Monte Carlo standard error

```{r}
#| echo: true
# Monte Carlo standard error N = 1,000
sqrt(var(mc_output_1000) /1000)

# Monte Carlo standard error N = 100,000
sqrt(var(mc_output_100000) /100000)


```

## Bootstrap resampling

```{r}
#| echo: true
n_boot = 5000
boot_output_1000 <- replicate(n_boot, 
                         mean(sample(mc_output_1000, N, replace = T)))

ggplot() + geom_density(aes(x = boot_output_1000))
quantile(boot_output_1000, p = c(0.025, 0.975))

boot_output_100000 <- replicate(n_boot, 
                         mean(sample(mc_output_100000, N, replace = T)))

ggplot() + geom_density(aes(x = boot_output_100000))
quantile(boot_output_100000, p = c(0.025, 0.975))
```

## Today

-   Microsimulation basics

-   Sampling

-   Convergence

-   [**Simulating decision trees**]{.underline}

## When to simulate decision tree?

-   Some probabilities, costs, or outcomes depend on baseline characteristics

-   Want to model individual-level variability

    -   What % of patients have better outcomes with the intervention?

## Basic procedure

-   Generate individuals with baseline characteristics

    -   Sample from a dataset or an approximation of the joint distribution

-   Calculate individual's probabilities, costs, outcomes (some of which depend on baseline characteristics)

-   Compute tree for that individual and store outcome

-   Aggregate

## Use case: transfusion-transmitted infections

-   Transfused patients receive some combination of red blood cells, platelets, and/or plasma

-   Infection risk can vary by product

-   More units transfused = more exposure risk

## Baseline characteristics

Data table derived from Swedish and Danish blood donors with number of red blood cells (RBC), platelet (PLT) and plasma (FFP) units transfused, 5-year age group, and sex.

```{r}
#| echo: true
t_cohort <- read.csv2("transfusion_cohort.csv", sep=" ")
n_cohort <- nrow(t_cohort) #number of rows
n_cohort
idx_sample <- sample(1:n_cohort, 8) #randomly sample 8 donors
t_simulants <- t_cohort[idx_sample,]; t_simulants
```

## Calculating probability of infection

```{r}
#| echo: true
prev = 0.08 # 8 in 100 donations infected 
p_transmit_by_prod <- c(0.5, 0.5, 0.7) # Transmissibility by product
names(p_transmit_by_prod) <- c("RBC","PLT","FFP")
p_transmit_by_prod

#function for individual risk of transmission
get_p_transmit <- function(prev, p_transmit_by_prod, 
                           units_rbc, units_plt, units_ffp){
  p_neg_unit = 1 - prev
  return(
    1 - (
      (1-p_transmit_by_prod['RBC']*(1-p_neg_unit^units_rbc))*
        (1-p_transmit_by_prod['PLT']*(1-p_neg_unit^units_plt))*
        (1-p_transmit_by_prod['FFP']*(1-p_neg_unit^units_ffp))
    ))}
```

## Simulating infection

```{r}
#| echo: true

#Calculate probability of transmission for each recipient
t_simulants <- t_simulants |>
  mutate(p_transmit = get_p_transmit(prev, p_transmit_by_prod, 
                                     units_rbc, units_plt, units_ffp))

#Simulate whether infection occured
v_rand <- runif(n=nrow(t_simulants)) #vector of random numbers
t_simulants |>
  mutate(infected = v_rand < p_transmit)
```

## TT-Zika parameters depend on age, sex, component mix

![](figs/simulated_decision_tree_zika.png)

## Recap

-   Microsims model individuals' pathways, allow for complex relationships between variables

-   Can be parameterized to estimate individual variability within population

-   While flexible, complex to parameterize and slow to compute

## Logistics

-   Complete reading before next class
-   **Assignment 2** Cohort state transition models due Friday, January 30
    -   **More time consuming than usual**
-   Office hours: Mondays 2:30pm to 3:30pm, room 1128
